name: Weekly Benchmark

on:
  schedule:
    # Run every Monday at 00:00 UTC
    - cron: '0 0 * * 1'
  workflow_dispatch: # Allow manual triggering

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  benchmark:
    name: Run Weekly Benchmarks
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Install Rust toolchain
      uses: actions-rust-lang/setup-rust-toolchain@v1
      with:
        toolchain: stable

    - name: Install benchmark tools
      run: |
        sudo apt-get update
        sudo apt-get install -y wrk curl
        # Install hey (alternative HTTP load testing tool)
        wget -q https://hey-release.s3.us-east-2.amazonaws.com/hey_linux_amd64
        chmod +x hey_linux_amd64
        sudo mv hey_linux_amd64 /usr/local/bin/hey

    - name: Cache cargo registry
      uses: actions/cache@v4
      with:
        path: ~/.cargo/registry
        key: ${{ runner.os }}-cargo-registry-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: |
          ${{ runner.os }}-cargo-registry-

    - name: Cache cargo index
      uses: actions/cache@v4
      with:
        path: ~/.cargo/git
        key: ${{ runner.os }}-cargo-index-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: |
          ${{ runner.os }}-cargo-index-

    - name: Build Actix app
      working-directory: ./actix-app
      run: cargo build --release

    - name: Build Axum app
      working-directory: ./axum-app
      run: cargo build --release

    - name: Run Docker benchmarks
      run: |
        # Install Docker if not available
        if ! command -v docker &> /dev/null; then
          echo "Docker not found, installing..."
          sudo apt-get update
          sudo apt-get install -y docker.io
        fi
        
        # Make scripts executable
        chmod +x ./docker_benchmark.sh
        chmod +x ./cpu_ram_benchmark.sh
        chmod +x ./benchmarks/*.sh
        
        # Run Docker benchmarks
        ./docker_benchmark.sh || echo "Docker benchmark failed, continuing..."

    - name: Run CPU & RAM benchmarks
      run: |
        # Run CPU and RAM intensive benchmarks
        ./cpu_ram_benchmark.sh || echo "CPU/RAM benchmark failed, continuing..."

    - name: Run standard benchmarks
      run: |
        # Make script executable
        chmod +x ./run_all_benchmarks.sh
        
        # Create results directory with timestamp
        RESULTS_DIR="benchmark_results_$(date +%Y%m%d)"
        mkdir -p "$RESULTS_DIR"
        
        # Run all benchmarks (simplified version to avoid conflicts)
        echo "Running lightweight benchmark suite..."
        
        # Start Actix server
        ./actix-app/target/release/actix-benchmark &
        ACTIX_PID=$!
        sleep 5
        
        # Run Actix light benchmark
        wrk -t4 -c100 -d30s http://127.0.0.1:8080/hello > "$RESULTS_DIR/actix_light.txt" 2>&1 || true
        
        # Run Actix heavy benchmark
        wrk -t2 -c50 -d20s http://127.0.0.1:8080/heavy > "$RESULTS_DIR/actix_heavy.txt" 2>&1 || true
        
        # Stop Actix server
        kill $ACTIX_PID || true
        sleep 2
        
        # Start Axum server
        ./axum-app/target/release/axum-benchmark &
        AXUM_PID=$!
        sleep 5
        
        # Run Axum light benchmark
        wrk -t4 -c100 -d30s http://127.0.0.1:8081/hello > "$RESULTS_DIR/axum_light.txt" 2>&1 || true
        
        # Run Axum heavy benchmark
        wrk -t2 -c50 -d20s http://127.0.0.1:8081/heavy > "$RESULTS_DIR/axum_heavy.txt" 2>&1 || true
        
        # Stop Axum server
        kill $AXUM_PID || true
        
        echo "Benchmarks completed"

    - name: Analyze and format results
      run: |
        RESULTS_DIR="benchmark_results_$(date +%Y%m%d)"
        REPORT_FILE="BENCHMARK_REPORT_$(date +%Y%m%d).md"
        
        # Create benchmark report
        cat > "$REPORT_FILE" << 'EOF'
        # Weekly Benchmark Report
        
        **Date:** $(date +%Y-%m-%d)
        **System:** GitHub Actions Runner (ubuntu-latest)
        
        ## Summary
        
        This report contains automated benchmark results comparing Actix and Axum web frameworks.
        
        ## Benchmark Results
        
        ### Actix Light Endpoint
        
        ```
        EOF
        
        if [ -f "$RESULTS_DIR/actix_light.txt" ]; then
          cat "$RESULTS_DIR/actix_light.txt" >> "$REPORT_FILE"
        else
          echo "No results available" >> "$REPORT_FILE"
        fi
        
        cat >> "$REPORT_FILE" << 'EOF'
        ```
        
        ### Actix Heavy Endpoint
        
        ```
        EOF
        
        if [ -f "$RESULTS_DIR/actix_heavy.txt" ]; then
          cat "$RESULTS_DIR/actix_heavy.txt" >> "$REPORT_FILE"
        else
          echo "No results available" >> "$REPORT_FILE"
        fi
        
        cat >> "$REPORT_FILE" << 'EOF'
        ```
        
        ### Axum Light Endpoint
        
        ```
        EOF
        
        if [ -f "$RESULTS_DIR/axum_light.txt" ]; then
          cat "$RESULTS_DIR/axum_light.txt" >> "$REPORT_FILE"
        else
          echo "No results available" >> "$REPORT_FILE"
        fi
        
        cat >> "$REPORT_FILE" << 'EOF'
        ```
        
        ### Axum Heavy Endpoint
        
        ```
        EOF
        
        if [ -f "$RESULTS_DIR/axum_heavy.txt" ]; then
          cat "$RESULTS_DIR/axum_heavy.txt" >> "$REPORT_FILE"
        else
          echo "No results available" >> "$REPORT_FILE"
        fi
        
        cat >> "$REPORT_FILE" << 'EOF'
        ```
        
        ## Docker Benchmark Results
        
        EOF
        
        # Include Docker results if available
        for file in docker_*.txt; do
          if [ -f "$file" ]; then
            echo "### $file" >> "$REPORT_FILE"
            echo '```' >> "$REPORT_FILE"
            cat "$file" >> "$REPORT_FILE"
            echo '```' >> "$REPORT_FILE"
            echo "" >> "$REPORT_FILE"
          fi
        done
        
        cat >> "$REPORT_FILE" << 'EOF'
        
        ## Notes
        
        - Benchmarks run on GitHub Actions runner (ubuntu-latest)
        - Results may vary based on runner load and available resources
        - For production comparisons, run benchmarks on dedicated hardware
        
        ---
        *Generated automatically by GitHub Actions*
        EOF
        
        echo "Report generated: $REPORT_FILE"

    - name: Create Pull Request with results
      uses: peter-evans/create-pull-request@v6
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        commit-message: 'chore: update weekly benchmark results'
        title: 'Weekly Benchmark Results - ${{ github.run_number }}'
        body: |
          ## Automated Weekly Benchmark Results
          
          This PR contains the benchmark results from the weekly automated run.
          
          **Run Date:** ${{ github.run_id }}
          **Workflow Run:** ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          
          ### What's included:
          - Standard benchmark results (light and heavy endpoints)
          - Docker benchmark results (if available)
          - CPU & RAM intensive benchmark results (if available)
          - Detailed benchmark report
          
          ### Review Instructions:
          1. Review the benchmark results in the report file
          2. Compare with previous weeks to identify trends
          3. Investigate any significant performance changes
          4. Merge this PR to update the benchmark history
          
          ---
          *This PR was created automatically by the weekly-benchmark workflow*
        branch: benchmark-results-${{ github.run_number }}
        delete-branch: true
        labels: |
          benchmark
          automated
        assignees: ${{ github.repository_owner }}
